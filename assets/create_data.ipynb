{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd1be207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding all images in the dataset...\n",
      "Found 112120 images\n",
      "Reading and processing CSV data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing conditions: 100%|██████████| 15/15 [13:53<00:00, 55.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train/validation/test splits...\n",
      "\n",
      "Dataset creation complete!\n",
      "\n",
      "Statistics by condition:\n",
      "--------------------------------------------------\n",
      "Condition            Available  Selected  \n",
      "--------------------------------------------------\n",
      "Cardiomegaly         1093       1000      \n",
      "Emphysema            892        892       \n",
      "Effusion             3955       1000      \n",
      "Hernia               110        110       \n",
      "Infiltration         9547       1000      \n",
      "Mass                 2139       1000      \n",
      "Nodule               2705       1000      \n",
      "Atelectasis          4215       1000      \n",
      "Pneumothorax         2194       1000      \n",
      "Pleural_Thickening   1126       1000      \n",
      "Pneumonia            322        322       \n",
      "Fibrosis             727        727       \n",
      "Edema                628        628       \n",
      "Consolidation        1310       1000      \n",
      "No Finding           60361      1000      \n",
      "--------------------------------------------------\n",
      "\n",
      "Total images in new dataset: 12679\n",
      "Training set: 8861 images\n",
      "Validation set: 1950 images\n",
      "Test set: 1868 images\n",
      "\n",
      "Class distribution in the dataset:\n",
      "Cardiomegaly: 1000 images\n",
      "Effusion: 1000 images\n",
      "Infiltration: 1000 images\n",
      "Mass: 1000 images\n",
      "Nodule: 1000 images\n",
      "Atelectasis: 1000 images\n",
      "Pneumothorax: 1000 images\n",
      "Pleural_Thickening: 1000 images\n",
      "Consolidation: 1000 images\n",
      "No Finding: 1000 images\n",
      "Emphysema: 892 images\n",
      "Fibrosis: 727 images\n",
      "Edema: 628 images\n",
      "Pneumonia: 322 images\n",
      "Hernia: 110 images\n",
      "\n",
      "Checking for patient overlap between splits:\n",
      "Train-Valid overlap: 0 patients\n",
      "Train-Test overlap: 0 patients\n",
      "Valid-Test overlap: 0 patients\n",
      "\n",
      "Gender distribution:\n",
      "M: 7023 images (55.4%)\n",
      "F: 5656 images (44.6%)\n",
      "\n",
      "Age distribution:\n",
      "Mean age: 48.3 years\n",
      "Median age: 51.0 years\n",
      "Range: 1 to 414 years\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_single_pathology_dataset(base_dir, output_dir, max_images_per_class=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Create a new dataset with only single-pathology images, organized by class\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory containing the original NIH dataset\n",
    "        output_dir: Output directory for the new dataset\n",
    "        max_images_per_class: Maximum number of images per pathology class\n",
    "        seed: Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Setup paths\n",
    "    csv_path = os.path.join(base_dir, 'Data_Entry_2017.csv')\n",
    "    new_dataset_dir = os.path.join(output_dir, 'single_pathology_dataset')\n",
    "    new_images_dir = os.path.join(new_dataset_dir, 'images')\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs(new_dataset_dir, exist_ok=True)\n",
    "    os.makedirs(new_images_dir, exist_ok=True)\n",
    "    \n",
    "    # Find all images in the NIH dataset structure\n",
    "    print(\"Finding all images in the dataset...\")\n",
    "    image_pattern = os.path.join(base_dir, 'images_*/images/*.png')\n",
    "    image_paths = glob.glob(image_pattern)\n",
    "    \n",
    "    # Create a mapping from image filename to full path for quick lookup\n",
    "    image_map = {os.path.basename(path): path for path in image_paths}\n",
    "    print(f\"Found {len(image_paths)} images\")\n",
    "    \n",
    "    # Read the CSV file\n",
    "    print(\"Reading and processing CSV data...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # List of pathologies we want to include in our dataset\n",
    "    conditions = [\n",
    "        'Cardiomegaly', 'Emphysema', 'Effusion', 'Hernia', 'Infiltration', \n",
    "        'Mass', 'Nodule', 'Atelectasis', 'Pneumothorax', 'Pleural_Thickening', \n",
    "        'Pneumonia', 'Fibrosis', 'Edema', 'Consolidation'\n",
    "    ]\n",
    "    \n",
    "    # Add 'No Finding' as a class\n",
    "    conditions.append('No Finding')\n",
    "    \n",
    "    # Initialize columns for each condition with zeros\n",
    "    for condition in conditions:\n",
    "        df[condition] = 0\n",
    "    \n",
    "    # Parse the 'Finding Labels' column to populate condition columns\n",
    "    for index, row in df.iterrows():\n",
    "        labels = row['Finding Labels'].split('|')\n",
    "        for condition in conditions:\n",
    "            if condition in labels:\n",
    "                df.at[index, condition] = 1\n",
    "    \n",
    "    # Add path information\n",
    "    df['path'] = df['Image Index'].apply(lambda x: image_map.get(x, ''))\n",
    "    \n",
    "    # Keep only rows where the image file was found\n",
    "    df = df[df['path'] != '']\n",
    "    \n",
    "    # Create a new dataframe for our single-pathology dataset\n",
    "    new_dataset = []\n",
    "    \n",
    "    # Add a directory for normal cases\n",
    "    os.makedirs(os.path.join(new_images_dir, 'No Finding'), exist_ok=True)\n",
    "    \n",
    "    # Statistics for reporting\n",
    "    stats = {condition: {'available': 0, 'selected': 0} for condition in conditions}\n",
    "    \n",
    "    # Create directories for each pathology class\n",
    "    for condition in conditions:\n",
    "        os.makedirs(os.path.join(new_images_dir, condition), exist_ok=True)\n",
    "    \n",
    "    # Process each condition\n",
    "    for condition in tqdm(conditions, desc=\"Processing conditions\"):\n",
    "        # Find single-pathology cases for this condition\n",
    "        if condition == 'No Finding':\n",
    "            condition_df = df[df['Finding Labels'] == 'No Finding']\n",
    "        else:\n",
    "            # Select rows where only this condition is present\n",
    "            condition_mask = df[condition] == 1\n",
    "            other_conditions_mask = df[[c for c in conditions if c != condition]].sum(axis=1) == 0\n",
    "            condition_df = df[condition_mask & other_conditions_mask]\n",
    "        \n",
    "        stats[condition]['available'] = len(condition_df)\n",
    "        \n",
    "        # Sample up to max_images_per_class images\n",
    "        if len(condition_df) > max_images_per_class:\n",
    "            condition_df = condition_df.sample(max_images_per_class, random_state=seed)\n",
    "        \n",
    "        stats[condition]['selected'] = len(condition_df)\n",
    "        \n",
    "        # Copy images to new directory\n",
    "        for _, row in tqdm(condition_df.iterrows(), \n",
    "                          desc=f\"Copying {condition} images\", \n",
    "                          total=len(condition_df),\n",
    "                          leave=False):\n",
    "            source_path = row['path']\n",
    "            image_filename = row['Image Index']\n",
    "            dest_path = os.path.join(new_images_dir, condition, image_filename)\n",
    "            \n",
    "            # Copy the image file\n",
    "            shutil.copy2(source_path, dest_path)\n",
    "            \n",
    "            # Add to our new dataset dataframe\n",
    "            new_row = row.copy()\n",
    "            new_row['pathology'] = condition\n",
    "            new_row['new_path'] = dest_path\n",
    "            new_dataset.append(new_row)\n",
    "    \n",
    "    # Convert the list to a dataframe\n",
    "    new_df = pd.DataFrame(new_dataset)\n",
    "    \n",
    "    # Save the new CSV file\n",
    "    new_csv_path = os.path.join(new_dataset_dir, 'single_pathology_dataset.csv')\n",
    "    new_df.to_csv(new_csv_path, index=False)\n",
    "    \n",
    "    # Create train/validation/test splits based on patient ID\n",
    "    print(\"Creating train/validation/test splits...\")\n",
    "    \n",
    "    # Get unique patient IDs\n",
    "    patient_ids = new_df['Patient ID'].unique()\n",
    "    \n",
    "    # Split patient IDs into train, validation, and test sets\n",
    "    train_ids, temp_ids = train_test_split(patient_ids, test_size=0.3, random_state=seed)\n",
    "    valid_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=seed)\n",
    "    \n",
    "    # Create dataframes for each split\n",
    "    train_df = new_df[new_df['Patient ID'].isin(train_ids)].copy()\n",
    "    valid_df = new_df[new_df['Patient ID'].isin(valid_ids)].copy()\n",
    "    test_df = new_df[new_df['Patient ID'].isin(test_ids)].copy()\n",
    "    \n",
    "    # Save split CSVs\n",
    "    train_df.to_csv(os.path.join(new_dataset_dir, 'train.csv'), index=False)\n",
    "    valid_df.to_csv(os.path.join(new_dataset_dir, 'valid.csv'), index=False)\n",
    "    test_df.to_csv(os.path.join(new_dataset_dir, 'test.csv'), index=False)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nDataset creation complete!\")\n",
    "    print(\"\\nStatistics by condition:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Condition':<20} {'Available':<10} {'Selected':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    for condition in conditions:\n",
    "        print(f\"{condition:<20} {stats[condition]['available']:<10} {stats[condition]['selected']:<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    print(f\"\\nTotal images in new dataset: {len(new_df)}\")\n",
    "    print(f\"Training set: {len(train_df)} images\")\n",
    "    print(f\"Validation set: {len(valid_df)} images\")\n",
    "    print(f\"Test set: {len(test_df)} images\")\n",
    "    \n",
    "    return {\n",
    "        'dataset_dir': new_dataset_dir,\n",
    "        'csv_path': new_csv_path,\n",
    "        'train_csv': os.path.join(new_dataset_dir, 'train.csv'),\n",
    "        'valid_csv': os.path.join(new_dataset_dir, 'valid.csv'),\n",
    "        'test_csv': os.path.join(new_dataset_dir, 'test.csv'),\n",
    "        'stats': stats\n",
    "    }\n",
    "\n",
    "def explore_new_dataset(dataset_info):\n",
    "    \"\"\"\n",
    "    Generate summary statistics and visualizations for the new dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset_info: Dictionary with dataset information from create_single_pathology_dataset\n",
    "    \"\"\"\n",
    "    # Load the CSV files\n",
    "    full_df = pd.read_csv(dataset_info['csv_path'])\n",
    "    train_df = pd.read_csv(dataset_info['train_csv'])\n",
    "    valid_df = pd.read_csv(dataset_info['valid_csv'])\n",
    "    test_df = pd.read_csv(dataset_info['test_csv'])\n",
    "    \n",
    "    # Print class distribution\n",
    "    print(\"\\nClass distribution in the dataset:\")\n",
    "    class_counts = full_df['pathology'].value_counts()\n",
    "    for pathology, count in class_counts.items():\n",
    "        print(f\"{pathology}: {count} images\")\n",
    "    \n",
    "    # Check that there's no patient overlap between splits\n",
    "    train_patients = set(train_df['Patient ID'].unique())\n",
    "    valid_patients = set(valid_df['Patient ID'].unique())\n",
    "    test_patients = set(test_df['Patient ID'].unique())\n",
    "    \n",
    "    print(\"\\nChecking for patient overlap between splits:\")\n",
    "    print(f\"Train-Valid overlap: {len(train_patients.intersection(valid_patients))} patients\")\n",
    "    print(f\"Train-Test overlap: {len(train_patients.intersection(test_patients))} patients\")\n",
    "    print(f\"Valid-Test overlap: {len(valid_patients.intersection(test_patients))} patients\")\n",
    "    \n",
    "    # Generate summary by gender\n",
    "    print(\"\\nGender distribution:\")\n",
    "    gender_counts = full_df['Patient Gender'].value_counts()\n",
    "    for gender, count in gender_counts.items():\n",
    "        print(f\"{gender}: {count} images ({count/len(full_df)*100:.1f}%)\")\n",
    "    \n",
    "    # Generate age distribution\n",
    "    age_mean = full_df['Patient Age'].mean()\n",
    "    age_median = full_df['Patient Age'].median()\n",
    "    age_min = full_df['Patient Age'].min()\n",
    "    age_max = full_df['Patient Age'].max()\n",
    "    \n",
    "    print(\"\\nAge distribution:\")\n",
    "    print(f\"Mean age: {age_mean:.1f} years\")\n",
    "    print(f\"Median age: {age_median:.1f} years\")\n",
    "    print(f\"Range: {age_min} to {age_max} years\")\n",
    "    \n",
    "    return {\n",
    "        'class_counts': class_counts,\n",
    "        'gender_counts': gender_counts,\n",
    "        'age_stats': {\n",
    "            'mean': age_mean,\n",
    "            'median': age_median,\n",
    "            'min': age_min,\n",
    "            'max': age_max\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the base directory to your dataset location\n",
    "    BASE_DIR = 'D:/healthcare'  # Change this to your dataset path\n",
    "    OUTPUT_DIR = 'D:/CV_project/processed'  # Change this to your desired output path\n",
    "    \n",
    "    # Create the dataset\n",
    "    dataset_info = create_single_pathology_dataset(\n",
    "        base_dir=BASE_DIR,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        max_images_per_class=1000\n",
    "    )\n",
    "    \n",
    "    # Explore the created dataset\n",
    "    explore_new_dataset(dataset_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healthcare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
